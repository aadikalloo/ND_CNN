{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A machine learning algorithm for classification of dermoscopic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dermoscopic imaging is a non-invasive imaging technique that allows for direct microscopic examination of the diagnostic features not seen by the naked eye in pigmented skin lesions[1]. Identification and retrieval of dermoscopic images is a task that is fundamental for the population of the Archive of the International Skin Imaging Collaboration (ISIC Archive)[2,3]. As the dermoscopic images of interest have no tags or other metadata indicating that they are dermoscopic in the database from which they are retrieved, identifying and sorting these images can become a very labor-intensive process. As a means toward alleviating the burden associated with sorting and labelling tens of thousands of images, an algorithm for automating said task is outlined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://github.com/aadikalloo/ND_CNN/raw/master/derm_vs_nderm_2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url='http://github.com/aadikalloo/ND_CNN/raw/master/derm_vs_nderm_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This system is composed of three main parts:\n",
    "    1. Reading images, pre-processing, and saving as an array\n",
    "        a. Extract color histogram data\n",
    "    2. Training a convolutional neural network to learn features of processed images\n",
    "    3. Training a random forest classifier to classify images based on color histogram data, using neural network    output classification as an input feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages:\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import time\n",
    "from imutils import paths\n",
    "import imutils\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(csv_path):\n",
    "\tfiles_df = pd.read_csv(csv_path) #read csv with pandas function\n",
    "\tonlyfiles = files_df['Filename'] #select only filename column\n",
    "\tstatus_df = files_df['Status']\n",
    "\treturn onlyfiles, status_df #return list of image files\n",
    "\n",
    "def extract_color_histogram(image, bins=(8*3, 8*3, 8*3)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()\n",
    "\n",
    "def readImage(num, file, image_path, wantStatus, status_df=[]):\n",
    "\tfile = image_path + file\n",
    "\timg0 = cv2.imread(file) #read image\n",
    "\tif num % 100 == 0:\n",
    "\t\tprint(num) #basic progress indicator\n",
    "\tcolor_hist = extract_color_histogram(img0)\n",
    "\timg = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY) #convert image to grayscale\n",
    "\tkernel = np.ones((2,2), np.float32)/4 #create 2x2 kernel for smoothing\n",
    "\timg = cv2.filter2D(img, -1, kernel) #smooth image\n",
    "\tlaplacian = cv2.Laplacian(img, cv2.CV_8U) #use laplacian filter (\"edge detector\") to find edges and lines\n",
    "\tlaplacian = cv2.filter2D(laplacian, -1, kernel) #smooth image\n",
    "\tlaplacian = cv2.GaussianBlur(laplacian, (3, 3), 0) #blur image\n",
    "\tlaplacian = (255 - laplacian) #invert color/gray values\n",
    "\tlaplacian = cv2.GaussianBlur(laplacian, (7, 7), 0) #blur image\n",
    "\tret, laplacian = cv2.threshold(laplacian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) #use Otsu adaptive thresholding to extract scale bar\n",
    "\tlaplacian = cv2.resize(laplacian, (200, 200)) #convert to 500x500 and return\n",
    "\tstatus = status_df[num]\n",
    "\treturn (laplacian, file, color_hist, status)\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\twantStatus = True\n",
    "\timage_path = 'image_folder' #location of images\n",
    "\tcsv_path = 'csv_path' #location of csv with filename and dermoscopy status; columns: Filename, Status\n",
    "\tlist_of_images, status_df = get_file_list(csv_path)\n",
    "\ttime1 = time.time()\n",
    "\tnum_cores = multiprocessing.cpu_count()\n",
    "\tresult_array = joblib.Parallel(n_jobs=num_cores)(joblib.delayed(readImage)(i, image, image_path, wantStatus, status_df) for i, image in enumerate(list_of_images))\n",
    "\ttime2 = time.time()\n",
    "\tprint('read function took %0.3f s' % ((time2-time1)*1))\n",
    "\tprint(\"Saving...\")\n",
    "\tnp.save('array_save_path', result_array)\n",
    "\tprint(\"Model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is used to resize, and apply convolutional filters, and append images to a 3D array. This results in images with dimensions 200px by 200px. The filters are used to \"pull out\" the scale bar. These scale bars are used as the primary feature recognized by the CNN when learning to classify dermoscopic images. The result of this step is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/aadikalloo/ND_CNN/raw/master/derm_processed_2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://github.com/aadikalloo/ND_CNN/raw/master/derm_processed_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_image_array(image_array):\n",
    "    image_array = image_array[..., 0]\n",
    "    image_array = np.dstack(image_array)\n",
    "    image_array = np.rollaxis(image_array, -1)\n",
    "    image_array = image_array[:, np.newaxis, :, :]\n",
    "    return image_array\n",
    "\n",
    "def load_data(csv_path, image_path):\n",
    "     #location of csv with filename and dermoscopy status; columns: Filename, Status\n",
    "    image_array_with_filenames = np.load(image_path)\n",
    "    filename_array = image_array_with_filenames[..., 1]\n",
    "    status_array = image_array_with_filenames[...,3]\n",
    "    allimages = reshape_image_array(image_array_with_filenames)\n",
    "    del image_array_with_filenames\n",
    "    random.seed(1149)\n",
    "    shuffled_indices = np.random.permutation(np.arange(len(filename_array)))\n",
    "    shuffled_images = allimages[shuffled_indices]\n",
    "    shuffled_df = filename_array[shuffled_indices]\n",
    "    shuffled_status = status_array[shuffled_indices]\n",
    "    shuffled_filedf = pd.DataFrame(shuffled_df, columns = ['Filename'])\n",
    "    shuffled_filedf['Status'] = shuffled_status\n",
    "    return shuffled_images, shuffled_filedf\n",
    "\n",
    "def split_datasets(shuffled_images, shuffled_df, train_proportion):\n",
    "    X_train = shuffled_images[0:math.floor(train_proportion*len(shuffled_df))]\n",
    "    X_test = shuffled_images[(math.floor(train_proportion*len(shuffled_df))+1):len(shuffled_df)]\n",
    "    df_train = shuffled_df[0:math.floor(train_proportion*len(shuffled_df))]\n",
    "    df_test = shuffled_df[(math.floor(train_proportion*len(shuffled_df))+1):len(shuffled_df)]\n",
    "    y_train = df_train['Status'].values\n",
    "    y_test = df_test['Status'].values\n",
    "    Y_train = np_utils.to_categorical(y_train, 2)\n",
    "    Y_test = np_utils.to_categorical(y_test, 2)\n",
    "    del shuffled_images, shuffled_df\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    return X_train, X_test, Y_train, Y_test, df_train, df_test    \n",
    "\n",
    "def create_model(num_conv_filters_layer1, num_conv_kernel_rows, num_conv_kernel_cols, num_conv_filters_layer2):\n",
    "    model = Sequential()\n",
    "    act = 'relu' #relu\n",
    "    model.add(Convolution2D(num_conv_filters_layer1, num_conv_kernel_rows, num_conv_kernel_cols, border_mode='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Convolution2D(num_conv_filters_layer1, num_conv_kernel_rows, num_conv_kernel_cols))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(num_conv_filters_layer2, num_conv_kernel_rows, num_conv_kernel_cols, border_mode='same'))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Convolution2D(num_conv_filters_layer2, num_conv_kernel_rows, num_conv_kernel_cols))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512)) #model.add(Dense(512))\n",
    "    model.add(Dropout(0.8)) #0.5\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dense(128)) #model.add(Dense(512)) #added\n",
    "    model.add(Dropout(0.5)) #0.5 #added\n",
    "    model.add(Activation(act)) #added\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_conv_filters_layer1 = 128\n",
    "    num_conv_filters_layer2 = 32\n",
    "    num_conv_kernel_rows, num_conv_kernel_cols = 3, 3\n",
    "    batch_size = 48 #originally 32\n",
    "    nb_classes = 2\n",
    "    nb_epoch = 100\n",
    "    data_augmentation = True\n",
    "    test_proportion = 0.25\n",
    "    train_proportion = 1 - test_proportion\n",
    "    img_rows, img_cols = 200, 200\n",
    "    img_channels = 1 #3\n",
    "    learning_rate = 0.001\n",
    "    n_folds = 10\n",
    "    image_path = 'array_save_path'\n",
    "    csv_path = 'csv_path'\n",
    "    print(\"Loading data...\")\n",
    "    Shuffled_images, Shuffled_filedf = load_data(csv_path, image_path)\n",
    "    print(\"Data loaded.\")\n",
    "    train_data, test_data, train_labels, test_labels, train_filenames, test_filenames = split_datasets(Shuffled_images, Shuffled_filedf, train_proportion)\n",
    "    print(\"Datasets split.\")\n",
    "    model = create_model(32, 3, 3, 32)\n",
    "    sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    print(\"Model created.\")\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(train_data, train_labels,\n",
    "                  batch_size=batch_size,\n",
    "                  nb_epoch=nb_epoch,\n",
    "                  validation_data=(test_data, test_labels),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        # this will do preprocessing and realtime data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True)  # randomly flip images\n",
    "\n",
    "        # compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied)\n",
    "        datagen.fit(train_data)\n",
    "\n",
    "        # fit the model on the batches generated by datagen.flow()\n",
    "        model.fit_generator(datagen.flow(train_data, train_labels,\n",
    "                            batch_size=batch_size),\n",
    "                            samples_per_epoch=25000,\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(test_data, test_labels))\n",
    "    model.save('save_model_path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network reads the image array of 200x200px images and trains using real-time data augmentation. GPU-acceleration was enabled to speed up training (NVIDIA Titan X). Before augmentation, 77000 images (inclusive of dermoscopic and non-dermoscopic) were used to train the network over 100 epochs (25000 images per epoch). A diagram of the network architecture is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/aadikalloo/ND_CNN/raw/master/nn7_plot.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://github.com/aadikalloo/ND_CNN/raw/master/nn7_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As summarized here, this architecture allowed the network to achieve validation accuracies (accuracy on data not used for training) of ~93.5% at the end of training: \n",
    "    \n",
    "    Epoch 95/100\n",
    "    25037/25000 - 118s - loss: 0.1511 - acc: 0.9436 - val_loss: 0.1738 - val_acc: 0.9356\n",
    "\n",
    "    Epoch 96/100\n",
    "    25008/25000 - 117s - loss: 0.1469 - acc: 0.9452 - val_loss: 0.1723 - val_acc: 0.9360\n",
    "\n",
    "    Epoch 97/100\n",
    "    25008/25000 - 117s - loss: 0.1498 - acc: 0.9439 - val_loss: 0.1709 - val_acc: 0.9362\n",
    "\n",
    "    Epoch 98/100\n",
    "    25037/25000 - 118s - loss: 0.1445 - acc: 0.9483 - val_loss: 0.1828 - val_acc: 0.9289\n",
    "\n",
    "    Epoch 99/100\n",
    "    25008/25000 - 117s - loss: 0.1458 - acc: 0.9457 - val_loss: 0.1771 - val_acc: 0.9348\n",
    "\n",
    "    Epoch 100/100\n",
    "    25037/25000 - 117s - loss: 0.1524 - acc: 0.9453 - val_loss: 0.1816 - val_acc: 0.9305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an accuracy of 93% was a major stride toward automating image classification, it was hypothesized that the use of an additional classifier could increase validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Random Forest classifier using nn output + color histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(results, image_array_path):\n",
    "\tresult_array = pd.read_csv(results)\n",
    "\tresult_array = result_array.iloc[:,0]\n",
    "\timage_array_with_filenames = np.load(image_array_path) #location of images\n",
    "\treturn result_array, image_array_with_filenames\n",
    "\n",
    "def form_hist_2D_array(image_array_with_filenames, result_array):\n",
    "\thist_data = image_array_with_filenames[..., 2]\n",
    "\thist_data = np.dstack(hist_data)\n",
    "\thist_data = hist_data.reshape(hist_data.shape[1:])\n",
    "\thist_data = np.rollaxis(hist_data, -1)\n",
    "\tstatus_array = image_array_with_filenames[...,3]\n",
    "\tstatus_array = status_array.tolist()\n",
    "\tstatus_array = np.asarray(status_array)\n",
    "\thist_data = np.insert(hist_data, 0, values=result_array, axis=1)\n",
    "\treturn hist_data, status_array\n",
    "\n",
    "def output_metric_results(crosstabresults, score):\n",
    "\tTN = crosstabresults[0][0]\n",
    "\tFN = crosstabresults[0][1]\n",
    "\tFP = crosstabresults[1][0]\n",
    "\tTP = crosstabresults[1][1]\n",
    "\tprint(crosstabresults)\n",
    "\tSensitivity = TP/(TP+FN)\n",
    "\tSpecificity = TN/(TN+FP)\n",
    "\tPPV = TP/(TP+FP)\n",
    "\tNPV = TN/(TN+FN)\n",
    "\tprint(\"Accuracy: \", score)\n",
    "\tprint(\"Sensitivity: \", Sensitivity)\n",
    "\tprint(\"Specificity: \", Specificity)\n",
    "\tprint(\"PPV: \", PPV)\n",
    "\tprint(\"NPV: \", NPV)\n",
    "\n",
    "def train_RF(hist_data, status_array, train_prop):\n",
    "\tarr_len = len(hist_data)\n",
    "\ttrain_len = math.floor(arr_len*train_prop)\n",
    "\tmodel = RandomForestClassifier(n_estimators=100, max_features=None, n_jobs=-1, verbose=True)\n",
    "\tmodel.fit(hist_data[0:train_len], status_array[0:train_len])\n",
    "\treturn model, arr_len, train_len\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\ttrain_prop = 0.75\n",
    "\tresults = 'nn_predictions.csv' #predictions\n",
    "\timage_array_path = 'array_path'\n",
    "\tpickle_loc = 'rf_save_path'\n",
    "\n",
    "\tresult_array, image_array_with_filenames = load_data(results, image_array_path)\n",
    "\thist_data, status_array = form_hist_2D_array(image_array_with_filenames, result_array)\n",
    "\tmodel, arr_len, train_len = train_RF(hist_data, status_array, train_prop)\n",
    "\tpreds = model.predict(hist_data[(train_len+1):arr_len])\n",
    "\tscore = accuracy_score(status_array[(train_len+1):arr_len], preds)\n",
    "\tjoblib.dump(model, pickle_loc) \n",
    "\tcrosstabresults = pd.crosstab(status_array[(train_len+1):arr_len], preds, rownames=['actual'], colnames=['preds:'])\n",
    "\toutput_metric_results(crosstabresults, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    preds:     0     1\n",
    "    actual            \n",
    "    0       4022    88\n",
    "    1        237  2673\n",
    "    \n",
    "    Accuracy:  0.953703703704\n",
    "    Sensitivity:  0.918556701031\n",
    "    Specificity:  0.978588807786\n",
    "    PPV:  0.96812749004\n",
    "    NPV:  0.944353134539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/aadikalloo/ND_CNN/raw/master/Versions/nn4.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://github.com/aadikalloo/ND_CNN/raw/master/Versions/nn4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over multiple testing phases, this classifier has consistently achieved accuracies >95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "References:\n",
    "    1. Vestergaard, M. E., Macaskill, P. H. P. M., Holt, P. E., & Menzies, S. W. (2008). Dermoscopy compared with naked eye examination for the diagnosis of primary melanoma: a meta‐analysis of studies performed in a clinical setting. British Journal of Dermatology, 159(3), 669-676.\n",
    "    2. Gutman, D., Codella, N. C., Celebi, E., Helba, B., Marchetti, M., Mishra, N., & Halpern, A. (2016). Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC). arXiv preprint arXiv:1605.01397.\n",
    "    3. International Skin Imaging Collaboration. www.isic-archive.com\n",
    "    4. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
